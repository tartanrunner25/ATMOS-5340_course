<img src='./images/class_logo.png' width=500px align='right' style='padding-left:30px'>

**Module 7**<br>
**ATMOS 5340: Environmental Programming and Statistics**<br>
**John Horel and Derek Mallia**<br>
<br>

> # Announcement: 
> Your 5th programming assignment on Panda, Numpy Arrays, and plotting is **due in two weeks.**

> # Today's Objective
> Introduce Python's Pandas library
> Discuss why we would want to use Pandas
> Reading in data with Pandas
> Use Pandas to manipulate some basic data sets
<br><br>


#  Python Pandas

Pandas is a data manipulation tool built on Python's Numpy module. Pandas introduces two new data type structures. The first data structure type is a Pandas *series*, which is a one dimensional array. The second data structure is a *'dataframe'*, which is similar to a 2-D NumPy array, except that it can hold multiple data types within it (strings, floats, integers, datetime objects, ect...). This features make Pandas particularly good for working with time series data. In addition, I've always found reading in text and csv data rather annoying in Python, but Pandas makes this task MUCH easier! For today, we will: 
- Read csv-formatted data into Python 
- Learn how to subset and slice dataframes 
- Aggegrate and group data
- Work with time objects in Pandas
- While not discussed here, plotting data from a Pandas dataframe is super easy! (We will learn about Python plotting next week)

**Before starting:** Make sure that you open up a Jupyter notebook session using OnDemand so you can interactively follow along with today's lecture!

    
<br><br>
---
---

#  Reading in data

As a starting point, lets load the appriopriate libraries for working with Pandas:

    import numpy as np
    import pandas as pd


For the purpose of this class, we will mostly be working with *dataframes* as we will mostly be working with 2D data sets. As a first step, lets fire up a linux session on a seperate browser tab, and copy the following file into your working directory. For todays lecture, it may be a good idea to create a directory called `module7_lecture` and then `cd` into it.

    mkdir module7_lecture
    cd module7_lecture
    cp /uufs/chpc.utah.edu/common/home/u0703457/public_html/dereks_homepage/Atmos_5340/class_files/module7_zoo.csv .


Now, lets return to our Jupyter notebook session. <br>
<br>
To read in a csv file, we will be using the `pd.read.csv()` function, which is similar to Python's default csv function, except that it is a bit less cumbersome to use! This function has a number of arguments that will allow this code to deal all sorts of csv files. For this lecture, we will just focus on a few key arguments:

>- `filepath_or_buffer`: name of file we are reading in
>- `sep`: how are values seperated in our csv file
>- `header`: Do we want to include our header? If left as blank, column names are assigned from the first row of our csv file.
>- `skiprows`: How many rows do we want to skip when reading in our file? (0-base index).

<br><br>
Other arguments for this function can be found here: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html
<br><br>
Lets read in our file now:

    my_zoo = pd.read_csv('module7_zoo.csv', delimiter = ',')
   
    print(my_zoo)
    >> animal  uniq_id  water_need
    >> 0   elephant     1001         500
    >> 1   elephant     1002         600
    >> 2   elephant     1003         550
    >> 3      tiger     1004         300
    ....
    >> 20  kangaroo     1021         430
    >> 21  kangaroo     1022         410
    
    
    type(my_zoo)
    >> <class 'pandas.core.frame.DataFrame'>
    
    
And thats it.... Read in data with Pandas is usually that easy! As seen in our print statement, we are working with a Pandas data frame, where the indices on the left are the index numbers of our 2D array, while the column names are defined using the column names from the first row of our csv file.
    
<br><br>
---
---

#  Selecting rows and columns

Selecting a specific row or column within a Pandas dataframe is fairly simple. To index a column, we just use the dataframe variable name, and subset the columns by using the name of the column that we would like to select:

    print(my_zoo['animal'])
    
    >> 0     elephant
    >> 1     elephant
    >> 2     elephant
    >> 3        tiger
    ....
    >> 20    kangaroo
    >> 21    kangaroo
    >> Name: animal, dtype: object
    
<br><br>   
To get the first 5 rows of our dataframe, we can slice our data frame with the following command:

    print(my_zoo[:3])
    
    >> animal  uniq_id  water_need
    >> 0  elephant     1001         500
    >> 1  elephant     1002         600
    >> 2  elephant     1003         550
    
<br><br>  
We can also combine both commands to subset our data from the first 3 rows of the 'animal' column:

    print(my_zoo[:3]['animal'])
    
    >> 0    elephant
    >> 1    elephant
    >> 2    elephant
    >> Name: animal, dtype: object

<br><br>   
What is we wanted to grab the name of our columns only, and save it as a list?

    print(list(my_zoo.columns))
    
    >> ['animal', 'uniq_id', 'water_need']
    
<br><br>    
You also have the ability to select multiple columns by simply inserting a list of column names as part of the subset command:

    print(my_zoo[['animal','uniq_id']])
    
    >> animal  uniq_id
    >> 0   elephant     1001
    >> 1   elephant     1002
    >> 2   elephant     1003
    ....
    >> 20  kangaroo     1021
    >> 21  kangaroo     1022

How would we subset our dataframe 'my_zoo' for the last 10 rows of the animal and water_need columns?
<br><br>  




What if we wanted save the rows for animals that have a water needed greater than or equal to 300?

    thirsty_animals = my_zoo[my_zoo['water_need'] >= 300]
    

    print(thirsty_animals)
    >>         animal  uniq_id  water_need
    >> 0   elephant     1001         500
    >> 1   elephant     1002         600
    >> 2   elephant     1003         550
    ...
    >> 20  kangaroo     1021         430
    >> 21  kangaroo     1022         410


<br><br> 

What if I just wanted the ID numbers for animals that had a water requirement between 300-400? How would I do this? What animal type most often requires this amount of water?


<br><br>


**Other useful functions and methods:**

You can also add new columns to dateframe easily using Pandas. For example, lets say we wanted to add a new column called 'age', which we would fill in later. We can simply do the following to accomplish this task:

    my_zoo['age'] = np.nan
    
    print(my_zoo)
    
    >>        animal  uniq_id  water_need  age
    >> 0   elephant     1001         500     NaN
    >> 1   elephant     1002         600     NaN
    >> 2   elephant     1003         550     NaN
    ...
    >> 20  kangaroo     1021         430     NaN
    >> 21  kangaroo     1022         410     NaN
    
Here, I just set the value in the column as `NaN`, to signify that these need to be filled in at a later time.

<br>
<br>

You can use the `.loc` method to subset for a specific row number using an index. Lets saw we now know the age for the 2nd elephant in our data frame. To fill this in, we can use the `.at` method:

    my_zoo.at[2,'age'] = '4'
    
Did it work?
<br><br>
Another handy function is the `.replace` method, which will replace all instances of a specified value within our data frame. For example:

    my_zoo = my_zoo.replace(np.nan, 5)
    
    print(my_zoo)
    >>         animal  uniq_id  water_need  age
    >> 0   elephant     1001         500     5.0
    >> 1   elephant     1002         600     5.0
    >> 2   elephant     1003         550     4.0
    >> 3      tiger     1004         300     5.0
    ....
    >> 20  kangaroo     1021         430     5.0
    >> 21  kangaroo     1022         410     5.0
    
Note that this command replaced all instances of `np.nan` with 5. Also note that the age of elephant #2 (ID 1002) remained unchanged since it was not equal to `np.nan`.



<br><br>
---
---

#  Aggregating data

Pandas dataframe structure makes it super easy to aggregate and manipulate data. For example, lets say we wanted to take an average of the water need for each animal type? We could this manually with this relatively short dataframe, but what if you needed to do this for a much larger zoo, with thousands of animals?!
Fortunately, this can be easily done in Python:

    avg_water = my_zoo.groupby('animal')['water_need'].agg(np.mean)
    
    print(avg_water)
    
    >> animal
    >> elephant    550.000000
    >> kangaroo    416.666667
    >> lion        477.500000
    >> tiger       310.000000
    >> zebra       184.285714
    >> Name: water_need, dtype: float64

<br><br>
We can also compute a bunch of other mathematical functions, simultaneously, in a single line!


    water_stats = my_zoo.groupby('animal')['water_need'].agg([np.mean,np.median,np.std,np.max,np.min])

    print(water_stats)
    
    >>            mean  median        std  amax  amin
    >> animal                                             
    >> elephant  550.000000     550  50.000000   600   500
    >> kangaroo  416.666667     410  11.547005   430   410
    >> lion      477.500000     460  93.941471   600   390
    >> tiger     310.000000     310  15.811388   330   290
    >> zebra     184.285714     220  65.791880   240    80


<br><br>
---
---

#  Working with data with timestamps

Now, lets work with a data that has a column for time. Meteorological data often contains information about some quanitity that is being measured/modeled, in addition to the time that the measurement/modeled value was made at.
<br><br>
Copy the following csv file into your working directory now using your linux window:

    cp /uufs/chpc.utah.edu/common/home/u0703457/public_html/dereks_homepage/Atmos_5340/class_files/lecture7_WBB.csv .
    
    
Now, lets take a quick peek at this before we read it in with Python:

    more lecture7_WBB.csv 
    

Do you see anything about this file that we may want to consider before reading it in with Pandas `pd.read_csv` function?

<br><br>


Next lets read in our file and print out some of the data....

    dat = pd.read_csv('lecture7_WBB.csv',sep=',',skiprows=6)
    
    print(dat)
    
    >>        Station_ID     Date_Time            air_temp_set_1  relative_humidity_set_1  wind_speed_set_1  wind_direction_set_1  wind_gust_set_1
    >> 0          WBB  11/30/2011 12:00 MST           41.83                    65.03              7.36                 275.9            12.71
    >> 1          WBB  11/30/2011 12:05 MST           42.15                    63.24              6.82                 283.9            13.49
    >> 2          WBB  11/30/2011 12:10 MST           42.40                    62.89              6.44                 300.8            12.88
    >> 3          WBB  11/30/2011 12:15 MST           41.92                    64.74              9.46                 292.5            13.56
    >> 4          WBB  11/30/2011 12:20 MST           41.61                    65.40              9.40                 290.3            16.67
    ..         ...                   ...             ...                      ...               ...                   ...              ...
    >> 572        WBB  12/02/2011 11:40 MST           35.74                    42.71              3.96                 260.9             6.76
    >> 573        WBB  12/02/2011 11:45 MST           34.97                    43.94              4.29                 262.5             5.79
    >> 574        WBB  12/02/2011 11:50 MST           36.59                    41.50              1.97                 234.7             4.25
    >> 575        WBB  12/02/2011 11:55 MST           37.33                    40.51              2.24                 252.9             4.05
    >> 576        WBB  12/02/2011 12:00 MST           38.01                    38.91              1.90                 235.7             3.47


Wow! Easy! Everything looks like it was properly formatted, at least visually. Lets double check through. Using the dtypes method, we can check the data type of each column in our 'dat' dataframe:

    print(dat.dtypes)
    >> Station_ID                  object
    >> Date_Time                   object
    >> air_temp_set_1             float64
    >> relative_humidity_set_1    float64
    >> wind_speed_set_1           float64
    >> wind_direction_set_1       float64
    >> wind_gust_set_1            float64
    >> dtype: object


Everything looks good except 'Date_Time' is being treated as an 'object' or in this case, a string. This won't be very helpful if we are trying to subset/aggregate/manipulate the data by time. Lets convert our dateframe 'Date_Time' column to a datetime64 object. 

    dat['Date_Time'] = pd.to_datetime(dat.Date_Time)
    
    print(dat.dtypes)
    >> Station_ID                         object
    >> Date_Time                  datetime64[ns]
    >> air_temp_set_1                    float64
    >> relative_humidity_set_1           float64
    >> wind_speed_set_1                  float64
    >> wind_direction_set_1              float64
    >> wind_gust_set_1                   float64
    

Also, as a sanity check, it may be worthwhile to print out the dataframe to make sure nothing weird happened to our times during the conversion process...
<br><br>
Now that our time column is properly formatted, we can easily manipulate our dateframe, such as resampling the data to different time itervals, or subsetting the dataframe based on a time range.

    dat_1hour = dat.resample('60Min', on='Date_Time').mean()

    print(dat_1hour)
                            
    >> Date_Time                     air_temp_set_1  relative_humidity_set_1  wind_speed_set_1  wind_direction_set_1  wind_gust_set_1                                                                                               
    >> 2011-11-30 12:00:00-07:00       41.070833                61.262500          8.825833            293.066667        15.224167
    >> 2011-11-30 13:00:00-07:00       37.112500                77.275833          7.932500            311.608333        12.490833
    >> 2011-11-30 14:00:00-07:00       37.794167                76.843333          5.360833            276.608333         8.716667
    >> 2011-11-30 15:00:00-07:00       38.309167                75.110833          5.049167            274.108333         9.271667
    ....
    >> 2011-12-02 10:00:00-07:00       34.388333                44.708333          1.977500            275.891667         3.862500
    >> 2011-12-02 11:00:00-07:00       36.105000                42.290833          2.545000            263.858333         4.686667
    >> 2011-12-02 12:00:00-07:00       38.010000                38.910000          1.900000            235.700000         3.470000


⚠️⚠️⚠️ Before moving on, is there something sloppy that I assumed here? ⚠️⚠️⚠️


<br><br> 

What can we do? Lets decompose our wind speed and direction into u- and v-wind components, and then take the average for each hour!
Then we can just convert our u- and v-wind components back into a wind speed and direction!

    u = -1*dat['wind_speed_set_1']*np.sin(dat['wind_direction_set_1']*(np.pi/180))
    v = -1*dat['wind_speed_set_1']*np.cos(dat['wind_direction_set_1']*(np.pi/180))
    
    dat['u_wind'] = u
    dat['v_wind'] = v
    
    dat_1hour = dat.resample('60Min', on='Date_Time').mean()
    
    dat_1hour['wind_speed_set_1'] = np.sqrt(dat_1hour['u_wind']**2 + dat_1hour['v_wind']**2)
    dat_1hour['wind_direction_set_1'] = (270-(np.arctan2(dat_1hour['v_wind'],dat_1hour['u_wind'])*(180/np.pi)))%360
    
    
<br><br>

Having a column formatted as a datetime64 object in a Pandas dataframe also makes it easy to filter/subset by time!
    
    print(dat[(dat['Date_Time'] >= '2011-11-30 12:00:00') & (dat['Date_Time'] < '2011-11-30 14:00:00')])
    
or

    print(dat.set_index('Date_Time').between_time('01:00:00','02:00:00'))
    
    
This is just one of the many examples and ways you can filter and subset data by time. For more examples, refer to google!

<br><br>
**Time conversion:** There may also be cases where you will need to convert your time objects between UTC and LST. For example, most environmental data sets are reported in UTC. However, it may be more intuitive to look at the data in LST, especially when looking at data such as temperature and relative humidity. Fortunately, Pandas makes it *relatively* easy to convert between time zones.

    new_time = dat['Date_Time'].dt.tz_convert('UTC')
    
Did anything happen?

<br><br>
**Cautionary tale:** Working with time objects can often be one of the more frustrating parts of programming, and this is often where a lot of bugs may arise. So always becareful when working with these data types! Also, do not get too discouraged. Even people like myself who have been programming for years often run into problems with time objects!

<br><br>
---
---

> # Want more practice!?<br>
> Check out the following webpages:<br>
> https://pandas.pydata.org/pandas-docs/version/0.15/tutorials.html<br>
> https://www.youtube.com/watch?v=dcqPhpY7tWk&t=113s<br>



